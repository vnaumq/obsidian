[[Loss]]

A [**loss function**](https://developers.google.com/machine-learning/glossary#loss-function) that calculates the square of the difference between actual [**label**](https://developers.google.com/machine-learning/glossary#label) values and the values that a [**model**](https://developers.google.com/machine-learning/glossary#model) predicts. For example, here's the calculation of L2 loss for a [**batch**](https://developers.google.com/machine-learning/glossary#batch) of five [**examples**](https://developers.google.com/machine-learning/glossary#example):

|Actual value of example|Model's predicted value|Square of delta|
|---|---|---|
|7|6|1|
|5|4|1|
|8|11|9|
|4|6|4|
|9|8|1|
||   |16 = L2 loss|

Due to squaring, L2 loss amplifies the influence of [**outliers**](https://developers.google.com/machine-learning/glossary#outliers). That is, L2 loss reacts more strongly to bad predictions than[**L1 loss**](https://developers.google.com/machine-learning/glossary#L1_loss). For example, the L1 loss for the preceding batch would be 8 rather than 16. Notice that a single outlier accounts for 9 of the 16.

[**Regression models**](https://developers.google.com/machine-learning/glossary#regression_model) typically use L2 loss as the loss function.

The [**Mean Squared Error**](https://developers.google.com/machine-learning/glossary#MSE) is the average L2 loss per example. **Squared loss** is another name for L2 loss.